# **学习报告**

# **机器学习 崔子航** 

## **一. Python：**

### **1.列表：**

1. append和extend的区别：append在列表后直接添加，若为多个元素，则添加为一个二级列表；extend相当于多次重复append一个元素，即使同时添加多个元素也不会出现二级列表。

2. pop，remove，del的区别：remove（）去除首个满足要求的元素；del str[i]根据下标删除元素；pop（）无参数时删除并返回最后一个元素，有参数则删除并返回对应下标的元素。注意：remove使用过后，下标会改变！
3. find和index的区别：index返回括号值的下标，后两个数可以限定查找范围；find可以检测字符串是否包含子字符串，返回其首个字符下标。且同样可以限定查找范围。
4. split()：用法：  
    a=input()
    print(a.split( ))#以空格为分界
    print(a.split('1'))#以 字符1 为分界
    #最后输出一个列表

### **2.元组：**

1. 元组中元素不可更改，但元组中的二级列表可以更改。

2. 当元组中只有一个元素时，要加逗号，否则会被当成数或者字符串。

### **3.字典：**

1. 键必须是不可变类型（元组，字符串），值可以使任意类型

2. dict{‘key’}=value可直接添加。

3. dict.keys()：获取所有键.

4. dict.values()：获取所有值.

5. dict.items（）：获取所有键值对.

6. update:可以传一个字典、关键字、列表、函数、修改键对应的值。

7. del :通过指定键删除 pop:通过指定值删除

8. 排序：sorted():下有详细说明


### **3. 函数：**

1. 空函数：可以用pass语句。pass可用作占位符，若没想好怎么写可以先用pass，让代码顺利运行。

2. 参数检查：个数不对会抛出TypeError。参数类型不对则无法检查。数据类型检查可以用内置函数isinstance（），如isinstance(object,
(classinfo)),classinfo可以是多种类型，需用括号括起，若object属于classinfo则返回True。

3. 返回值：可以返回多个值(列表、字典、元组)。

4. 位置参数：参数必须按位置输入。

5. 默认参数：必须在必选参数之后，且必须指向不变对象。若为可变对象，默认参数会被当做一个变量，函数多次调用默认参数时，可能会修改其值，可以使其指向None。

6. 可变参数：当不确定函数有多少个参数时(0个也行)，调用时可以先组装一个list或者tuple，或者加一个*，调用时自动组装。

7. 关键字参数：使用两个**，允许传入任意参数（包括0）。不需要考虑参数顺序。用法类似可变参数。

8. 命名关键字参数：使用一个*，仅允许传入相同名称的参数。

### **4. 高阶函数：**

1. map()：接收一个函数和一个可迭代对象，从可迭代对象中读取数据作用于函数。(貌似函数只可接收一个参数)

2. 惰性序列：直到被使用时才进行计算。

3. reduce():接收一个函数和一个可迭代对象，将可迭代对象的前两个参数输给函数，并将得到的结果与下一个参数输给函数。(函数需接收两个参数)

4. from  import :如 from functools import reduce ,类似精准选择

5. 匿名函数lambda：使用关键字lambda定义，后跟参数，‘ : ’，和简单的表达式，返回值为表达式计算的结果，主要用于简写逻辑简单的函数。

### **5.类和对象：**

1. 对象是类的实例，类是对象的抽象。类是制造汽车的图纸，对象就是汽车。

2. 类的组成：类名，属性（特征？特性？），方法 （实现功能？）

3. 类是具有一组相同或相似 属性 和  方法 的一系列对象的集合。

4. 定义类：使用class关键字定义，例如：

    class Person:   #类名，首字母建议大写
        name = 'czh'  #类属性  
        age ='19'
          #…………

    def study(self):
         pass #具体方法
    
5. 创建对象（类的实例化）：
    czh = Person()

6.实例方法（归于类的实例所有）:类的内部，使用def关键字可以定义一个实例方法，且第一个参数必须是self（可以为其他，但必须有），方法内通过类似self.xx定义属性为实例属性，且会屏蔽同名类属性。（黑人问号脸.jpg）

7.  ___init___：初始化实例属性(类似于函数中的参数？)，创建对象时自动调用。例:
    class Person():
        def __init__(self,name,age,heigeht):
            self.name = name
            self.age = age
            self.height = height
    czh=Person('czh','19','180')
    print(czh)
    输出即可

8. 更可搭配使用：

    def eat(food):
        print({self.name}喜欢吃{food})  

9. 理解self：self和对象指向同一个内存地址，（self就是对象的引用？）；若只有self，则不需要输入参数；调用方法时解释器自动把对象传递给self。

### **6.运算符：**

1. ** 表示乘方

2. & | ^ ：将数字转化为二进制后，每一位进行比较（按位取反），&有0就是0，|有1就是1，^两数相同就是0，不同就是1。

### **7.内置函数：**

1. round（）：输入两位数，第二位为保留小数点位数，默认为0，取近似值，但并不是四舍五入。

2. abs（）：

3. pow(x,y,z)：三个参数，返回x的y次方对z取模的值

4. max（）：输入一个序列，返回最大值。

5. sum（iterable，x）：两个参数，第一个为一个可迭代序列，x默认为0。返回序列之和与x的和。

6. eval（expression[,globals[,locals]]）：动态执行的函数（？黑人问号脸.JPG）（可以将字符串当成有效的表达式来求值并返回结果）,先输入一个表达式（甚至可以调用函数）。

7. int（），float（），bool（），str（）。

8. chr（）（range(256）：数字转字符，将输入的整数（10进制或者16进制）按ASCII码转化为字符。

9. bin（）：将十进制转二进制，hex（）：将十进制转换十六进制，oct（）：将十进制转八进制。

10. list（）：将元组转列表，tuple（）：将列表转元组，dict（）：创建一个字典。

11. bytes（）：转为字节数组，要多输入一个编码类型

12. set（）：无序（不可用切片索引，可用sorted排序）不重复的元素集合。以下均为set（）使用的函数：

13. .add():

14. .clear():列表字典也可用

15. difference（）：两个集合a，b的差集（a中存在，b中不存在），a.difference（b）等价于a-b。

16. intersection():交集，等价于a&b

17. union并集 等价于a|b

18. pop（）：没有参数，随机移除并获取某个参数

19. discard（）：移除指定元素

20. update（）：a.update（b）将b加到a中

### **8.序列方法：**

1. all（）：用于返回可迭代参数中所有元素是否都为true（除了0，空，false），否则返回false。（空列表或空元祖是true）

2. any（）：有一个为true就返回true。（空列表元组为false）

3. sorted（,reverse=false）：默认升序，返回一个新的列表，不修改原本对象。对任意可迭代对象使用。

4. sort（）：list.sort（），默认升序，且改变此对象，因不可对元组使用。

5. reverse（）：对列表使用，特性同上。

6. range（start，end，step）：可用于创建一个整数列表。，step默认为1.

7. zip（）：将可迭代对象对应地打包为一个个元组，返回一个长度与最短对象相同的列表，可用list（）或*将zip解压。

8. enumerate（）：将可遍历对象（？）组合为一个索引序列，同时列出数据和下标。第二个参数为起始下标。	

### **9.魔术方法（函数名前后都有双下划线）：**

1. __init__：初始化一个类

2. __str__： 直接输出对象时会输出地址，想要输出其信息，可用__str__

3. __new__：创建一个实例对象

<<<<<<< HEAD
### **10.梯度下降：**

=======
## **二. 机器学习：**

### **1.梯度下降：**
>>>>>>> 818767b0617c587cf45e3a77b050d304dc09066a
1. batch：批处理。此梯度下降法需要多次遍历整个数据集，计算量大，只能找到局部最低点（和选取的初位置有关），在损失函数图像为凸函数时，总能下降到最低点（函数光滑下降）。

2. θ_j≔θ_j-α ∂/(∂θ_j ) J(θ_0,θ_1 )(j=0,1)。
	1. α为学习效率（速率？）
	2. 其后为J的偏导数（代表斜率？），若自变量大于极小值点，此项为正，会使自变量向极小值点靠近，靠近过程中，此项不断减小，使接近速度不断减小，慢慢趋近于极小值点。若自变量小于极小值点也同理。在极小值点时偏导数为0，θ不再变化。
	3. α的选择：过小需要计算的次数太多，过大可能会在接近极小值点过程中越过该点，并来回摆动，难以趋近。
	4. θ的更新： 
需要同步更新，否则更新θ0后会影响θ2

<<<<<<< HEAD
### **11.k邻近法：**

=======
### **2.k邻近法：**
>>>>>>> 818767b0617c587cf45e3a77b050d304dc09066a
1. k邻近法是一种分类方法，计算新的数据与已有的数据的距离，并取前k个，按照其中不同类型的概率确定新数据的类型。

2. k值的选择很重要，不同的k值可能会得出不同的结果。

3. 距离用距离公式，多个特征用欧氏距离。
