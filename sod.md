# **显著性检测**

## **一.综述:**

1. 自然场景中显著物体的检测和分割，通常被称为显著物体检测，一般分为两个阶段：
    1. 检测最显著的对象。
    2. 分割该对象的准确区域。

2. 模型标准：
    1. 良好的性能：拥有较高的准确率和精确度。
    2. 高分辨率：显著图应高分辨率或全分辨率地突出物体并保留原始图像信息。
    3. 高效：作为其他复杂过程的前段，模型应该快速高效地检测显著对象。

3. 主要方法：多尺度的特征提取与融合；增大感受野。

4. 现存缺陷：由于对象内部的复杂性以及卷积和池化操作的跨步导致的边界不准确，预测的显著性映射仍然存在预测不完全的问题。

>即预测结果精度不够，题目要求就是限制模型大小和运算速度的前提下尽可能的提升精度。

## **二.代码:**

1. 找了点代码，目前还是u2net的效果最好，显著图清晰，其他的都比较模糊，甚至还有全黑的图片。也有效果好的算法不过没有开源。
![](images\2021-02-21-16-26-34.png)
![](images\2021-02-21-16-26-43.png)
![](images\2021-02-21-16-27-15.png)
![](images\2021-02-21-16-33-51.png)
![](images\2021-02-21-16-34-13.png)

# **attention注意力机制**

## **一.综述:**

1. 当神经网络来处理大量的输入信息时，也可以借助人脑的注意力机制，只选择一些关键的信息输入进行处理，用来提高神经网络的效率。在目前的神经网络模型中，可以将max pooling和gating机制近似地看作是自下而上的基于显著性的注意力机制。此外，自上而下的聚焦式注意力也是一种有效的信息选择方法。例如：给定一篇很长的文章，然后就此文章的内容进行提问，提出的问题只和文章中某个段落中的一两个句子相关，其余都无关的。为了减小神经网络的计算代价，只需要把相关的片段挑选出来让后续的神经网络来处理，而不需要把所有文章内容都输入到神经网络中。

>模拟人脑的注意力机制，只处理关键信息以提高效率。

## **二.基础知识**

1. 计算：
    1.在所有输入信息上计算注意力分布。
    2.根据注意力分布来计算输入信息的加权平均。

2. 注意力分布：为了实现选择特定的信息进行处理，需要引入一个与任务相关的**查询向量q**，并且通过一个**打分函数**计算不同信息向量与查询向量的相关性。
    1.Soft Attention注意力机制：
    ![](images\2021-02-21-14-34-00.png)
    
    >  即通过softmax函数来计算在给定x和q时选择x的概率。其中αi被称为注意力分布。S(xi,q)是注意力打分函数。
    
    2.各种打分函数：
    ![](images\2021-02-21-14-37-50.png)
    ![](images\2021-02-21-14-39-44.png)
    
3. 加权平均：
    1.软注意力机制：
    ![](images\2021-02-21-14-45-15.png)
    
    > 所有输入向量与注意力分布乘积的和。
    
    两种模式
    
    ![](images\2021-02-21-14-50-01.png)
    2.硬注意力机制：
    1）直接选择概率最大的输入向量。
    2）在注意力分布上随机采样的方式。
    缺点：使用最大或随机采样，损失函数与注意力分布之间的函数不可导，无法进行反向传播。
    3.键值对注意力：可以使用键值对格式来表示输入信息，其中键用来计算注意力分布，值用来计算聚合信息。
    4.多头注意力：运用**多个查询向量q**来平行计算从输入信息中选取多组信息，每个注意力关注输入信息的不同部分。
    5.自注意力:减少对外部信息的依赖，尽可能地利用特征内部固有的信息进行注意力的交互。
    
    ![70bf7e72dbe39c50e40792984bec82d5.png](images\70bf7e72dbe39c50e40792984bec82d5.png)
    
    

## **三.注意力机制在计算机视觉中的应用:** 

1.注意力机制没有严格的的数学定义，例如传统的局部图像特征提取、滑动窗口方法等都可以看做一种注意力机制。在神经网络中，注意力机制通常是一个额外的神经网络，能够硬性的选择输入某些部分，或者给输入的不同部分分配不同的权重。

>只要是能够从大量信息中筛选出有用的信息，就能够称为注意力机制。

2.注意力域：空间域(spatial domain)，通道域(channel domain)，混合域(mixed domain)，时间域(time domain)。

3. 空间域:Spatial Transformer Networks:CNN中池化层压缩信息，该网络设计一个名为spatial transformer的模块对图片的空间域信息做对应的空间变换。
    >缺点：忽略通道域信息，在网络中可解释性不强。
    模型结构：
    ![](images\2021-02-21-15-29-21.png)
    >模块中的定位网络会生成采样矩阵，并作用于原图进行旋转放缩。
    
4. 通道域：
    1. 通过信号变换的角度理解
       ![](images\2021-02-21-15-33-25.png)
       
       >任何信号都可以写为正弦波的线性组合。
       傅里叶变换：https://zhuanlan.zhihu.com/p/19763358
       CNN中初始输入有三个通道（RGB），经过卷积层后通道数会增加，可以理解为**卷积核的卷积操作类似于对信号进行傅里叶变换**，从而将信息从单个通道分成n个卷积核上的信号分量。如果我们给每个通道上的信号都增加一个权重，来代表该通道与关键信息的相关度的话，这个权重越大，则表示相关度越高，也就是我们越需要去注意的通道了。
       >通道域的注意力是对一个通道内的信息直接全局平均池化，忽略每一个通道内的局部信息.
    2.  网络：SEnet
        结构：
        ![](images\2021-02-21-15-45-35.png)
        ![](images\2021-02-22-13-41-15.png)
    >通过注意力模块学习每个通道的权重。
    FC：全连接层
    
    SKNet:灵感来源是，我们在看不同尺寸不同远近的物体时，视觉皮层神经元接受域大小是会根据刺激来进行调节的。那么对应于CNN网络，一般来说对于特定任务特定模型，卷积核大小是确定的，那么是否可以构建一种模型，使网络可以根据输入信息的多个尺度自适应的调节接受域大小呢？
    >select kernel：根据输入信息自适应调节卷积核大小。
    
    Split，Fuse，Select
    ![](images\2021-02-22-14-23-32.png)
    GSoPNet:
    ![](images\2021-02-22-14-06-40.png)
    协方差矩阵:https://www.cnblogs.com/chaosimple/p/3182157.html

5.混合域：将空间域通道域的注意力机制混合
    网络：Residual attentionnetwork for image classification（没找到代码）
    cbam模块：
    ![](images\2021-02-22-14-30-50.png)
    channel attention module:
    ![](images\2021-02-22-14-31-46.png)
    ![](images\2021-02-22-14-34-43.png)
    Spatial attention module:
    ![](images\2021-02-22-14-35-11.png)
    ![](images\2021-02-22-14-36-14.png)

6.时间域：用于视频。

7.Pyramid Attention:

![](images\2021-02-22-14-36-53.png)
![](images\2021-02-22-14-37-30.png)

8.Co Attention:处理成对输入。

9.Cross Attention。

10.Global vs. Local Attention.

11.Compositional Attention.

12.Dual Attention

13.self-attention：

![img](images\20200411172254268.png)

1. 计算q，k之间的相似度，常见的函数有点积、拼接等
2. 使用softmax得到注意力分布
3. 将注意力分布与v加权求和，得到最终的attention value

## **其他**

1. 抠图：
    ![](images\2021-02-21-16-38-55.png)
    效果：
    ![](images\2021-02-21-17-11-54.png)
    ![](images\2021-02-21-17-12-06.png)
    ![](images\2021-02-21-17-12-17.png)
    ![](images\2021-02-21-17-12-30.png)
    ![](images\2021-02-21-17-12-39.png)
    ![](images\2021-02-21-17-12-50.png)

2. iou代码：
    ![](images\2021-02-21-19-47-14.png)
    ![](images\2021-02-22-14-43-50.png)